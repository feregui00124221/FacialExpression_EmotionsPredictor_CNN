{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TdZn7z0Oa8QL"
   },
   "source": [
    "# RED NEURONAL CONVOLUCIONAL - PREDICCIÓN DE EXPRESIONES FACIALES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cbz_47OWeKbb"
   },
   "source": [
    "## Acerca del conjunto de datos\n",
    "Los datos consisten en imágenes de rostros en escala de grises de 48 x 48 píxeles. Los rostros se han registrado automáticamente de modo que estén más o menos centrados y ocupen aproximadamente la misma cantidad de espacio en cada imagen.\n",
    "\n",
    "La tarea consiste en categorizar cada rostro en función de la emoción que se muestra en la expresión facial en una de siete categorías (0 = Enfado, 1 = Disgusto, 2 = Miedo, 3 = Felicidad, 4 = Tristeza, 5 = Sorpresa, 6 = Neutral). El conjunto de entrenamiento consta de 28.709 ejemplos y el conjunto de prueba público consta de 3.589 ejemplos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLcF_f7jQ2Ou"
   },
   "source": [
    "## Importación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYbMhO2BbF8S"
   },
   "source": [
    "### Importación de la biblioteca de descarga del dataset de expresiones faciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z4Qjl9Rzx84D",
    "outputId": "f0de23c0-731a-466a-c800-1a8a7b9d7aac"
   },
   "outputs": [],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mT1_L98Q4FT"
   },
   "source": [
    "### Importación del dataset al entorno local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5vxx1dxrQ9vY",
    "outputId": "6a8b2060-7e74-42fe-88c0-cc750d114b89"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import kagglehub\n",
    "\n",
    "# shutil.rmtree(\"/root/.cache/kagglehub\", ignore_errors=True)\n",
    "# shutil.rmtree(\"./dataset\", ignore_errors=True)\n",
    "\n",
    "# Ruta local del dataset organizado\n",
    "dataset_local_path = \"./dataset\"\n",
    "\n",
    "# Verificar si el dataset ya existe localmente\n",
    "if os.path.exists(dataset_local_path) and len(os.listdir(dataset_local_path)) > 0:\n",
    "  print(f\"El dataset ya existe en el entorno local: {dataset_local_path}\")\n",
    "else:\n",
    "  print(\"El dataset no se encontró en el entorno local. Procediendo a descargarlo...\")\n",
    "\n",
    "  # Ruta donde se descargará el dataset de AffectNet\n",
    "  dataset_donwload_path = kagglehub.dataset_download(\"noamsegal/affectnet-training-data\")\n",
    "\n",
    "  # Verificar si la descarga contiene las carpetas esperadas\n",
    "  if os.path.exists(dataset_donwload_path):\n",
    "    print(f\"El dataset ha sido descargado en {dataset_donwload_path}\")\n",
    "\n",
    "    raw_download_dataset_path = os.path.join(dataset_local_path, \"raw_download\")\n",
    "\n",
    "    # Mover las carpetas a un directorio organizado\n",
    "    os.makedirs(raw_download_dataset_path, exist_ok=True)\n",
    "\n",
    "    # Move the contents of the source folder\n",
    "    for item in os.listdir(dataset_donwload_path):\n",
    "\n",
    "      if item in [\"contempt\", \"disgust\", \"fear\"]:\n",
    "        continue\n",
    "\n",
    "      source_item = os.path.join(dataset_donwload_path, item)\n",
    "      destination_item = os.path.join(raw_download_dataset_path, item)\n",
    "      shutil.move(source_item, destination_item)  # Move the file\n",
    "\n",
    "    # Eliminar el dataset descargado\n",
    "    shutil.rmtree(\"/root/.cache/kagglehub\", ignore_errors=True)\n",
    "\n",
    "    print(f\"Contenido del dataset descargado movido a la carpeta {raw_download_dataset_path}\")\n",
    "    print(f\"Dataset temporal contenido en cache eliminado exitosamente\")\n",
    "  else:\n",
    "    print(\"No se encontraron las carpetas esperadas en el dataset descargado. Revisa el proceso de descarga.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrkXpcG_ChTR"
   },
   "source": [
    "### Ordenado del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qkz_GTxiCjAR",
    "outputId": "42e50e58-5e73-4968-a916-e84ee3ec0353"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "train_path = os.path.join(dataset_local_path, \"train\")\n",
    "test_path = os.path.join(dataset_local_path, \"test\")\n",
    "raw_download_path = os.path.join(dataset_local_path, \"raw_download\")\n",
    "\n",
    "# Crear las carpetas de train y test\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(test_path, exist_ok=True)\n",
    "os.makedirs(raw_download_path, exist_ok=True)\n",
    "\n",
    "if os.path.exists(train_path) and os.path.exists(test_path) and len(os.listdir(train_path)) > 0 and len(os.listdir(test_path)) > 0:\n",
    "  print(f\"Las carpetas de train y test ya existen en el entorno local: {train_path} y {test_path}\")\n",
    "else:\n",
    "  print(\"Las carpetas de train y test no se encontraron en el entorno local. Procediendo a organizar el dataset...\")\n",
    "\n",
    "  # Iterar sobre las subcarpetas en raw_download (cada emoción)\n",
    "  for emotion_folder in os.listdir(raw_download_path):\n",
    "    emotion_path = os.path.join(raw_download_path, emotion_folder)\n",
    "\n",
    "    # Saltar si no es una carpeta\n",
    "    if not os.path.isdir(emotion_path):\n",
    "      continue\n",
    "\n",
    "    # Crear subcarpetas en train y test\n",
    "    train_emotion_path = os.path.join(train_path, emotion_folder)\n",
    "    test_emotion_path = os.path.join(test_path, emotion_folder)\n",
    "    os.makedirs(train_emotion_path, exist_ok=True)\n",
    "    os.makedirs(test_emotion_path, exist_ok=True)\n",
    "\n",
    "    # Listar todas las imágenes en la carpeta actual\n",
    "    images = [img for img in os.listdir(emotion_path) if img.endswith(('.jpg', '.png'))]\n",
    "\n",
    "    # Mezclar las imágenes para asegurar aleatoriedad\n",
    "    random.shuffle(images)\n",
    "\n",
    "    # Calcular división 80%-20%\n",
    "    split_index = int(len(images) * 0.8)\n",
    "    train_images = images[:split_index]\n",
    "    test_images = images[split_index:]\n",
    "\n",
    "    # Copiar imágenes a las carpetas correspondientes\n",
    "    for img in train_images:\n",
    "      shutil.copy(os.path.join(emotion_path, img), os.path.join(train_emotion_path, img))\n",
    "    for img in test_images:\n",
    "      shutil.copy(os.path.join(emotion_path, img), os.path.join(test_emotion_path, img))\n",
    "\n",
    "    print(f\"Procesado '{emotion_folder}': {len(train_images)} imágenes en train, {len(test_images)} imágenes en test.\")\n",
    "\n",
    "  print(\"Reorganización completada.\")\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "  total_size = 0\n",
    "  for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "    for file in filenames:\n",
    "      file_path = os.path.join(dirpath, file)\n",
    "      # Add file size\n",
    "      total_size += os.path.getsize(file_path)\n",
    "  return total_size\n",
    "\n",
    "folder_size = get_folder_size(train_path)\n",
    "\n",
    "# Convert size to a readable format (e.g., MB)\n",
    "print(f\"Folder size: train folder -> {folder_size / (1024 * 1024):.2f} MB\")\n",
    "\n",
    "folder_size = get_folder_size(test_path)\n",
    "\n",
    "# Convert size to a readable format (e.g., MB)\n",
    "print(f\"Folder size: test folder -> {folder_size / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJ9r_4cMZNUY"
   },
   "source": [
    "### Instalación de OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vzsOXOt5ZP9y",
    "outputId": "d1cc7ed4-dd3a-4845-9db0-b965e7ab5466"
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWidMTaPZSRU"
   },
   "source": [
    "### Visualización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "dxfAxt0iZUMi",
    "outputId": "ff28df06-259d-4193-d129-985a7cdf128c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Function to describe image properties\n",
    "def get_image_properties(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale\n",
    "    if image is None:\n",
    "        return {\"Error\": \"Could not load image\"}\n",
    "\n",
    "    # Calculate properties\n",
    "    height, width = image.shape\n",
    "    size = os.path.getsize(image_path)  # File size in bytes\n",
    "    mean_intensity = image.mean()  # Mean pixel intensity\n",
    "    min_intensity = image.min()  # Min pixel intensity\n",
    "    max_intensity = image.max()  # Max pixel intensity\n",
    "\n",
    "    return {\n",
    "        \"Dimensions\": f\"{width}x{height}\",\n",
    "        \"File Size (KB)\": f\"{size / 1024:.2f}\",\n",
    "        \"Mean Intensity\": f\"{mean_intensity:.2f}\",\n",
    "        \"Min Intensity\": min_intensity,\n",
    "        \"Max Intensity\": max_intensity,\n",
    "    }\n",
    "\n",
    "# Verify if the training folder exists\n",
    "if not os.path.exists(train_path) or len(os.listdir(train_path)) == 0:\n",
    "    print(\"The training folder is not found. Please check the dataset structure.\")\n",
    "else:\n",
    "    print(\"Visualizing dataset examples...\")\n",
    "\n",
    "    # List available classes\n",
    "    classes = os.listdir(train_path)\n",
    "    classes.sort()  # Ensure classes are in alphabetical order\n",
    "    print(f\"Classes found: {classes}\")\n",
    "\n",
    "    print(\"Visualizing examples from each class with properties:\")\n",
    "    # Display an example from each class with properties\n",
    "    fig, axes = plt.subplots(1, len(classes), figsize=(15, 5))\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_folder = os.path.join(train_path, class_name)\n",
    "        if os.path.isdir(class_folder):\n",
    "            # Get the first image from the class\n",
    "            example_image_path = os.path.join(class_folder, os.listdir(class_folder)[0])\n",
    "            image = cv2.imread(example_image_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale\n",
    "\n",
    "            # Display the image\n",
    "            axes[i].imshow(image, cmap=\"gray\")\n",
    "            axes[i].axis(\"off\")\n",
    "            axes[i].set_title(class_name)\n",
    "\n",
    "            # Get and print image properties\n",
    "            properties = get_image_properties(example_image_path)\n",
    "            print(f\"\\nClass: {class_name}\")\n",
    "            for prop, value in properties.items():\n",
    "                print(f\"{prop}: {value}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNaBVbusbaAv"
   },
   "source": [
    "## Preparación de los datos para el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XksRCx1Mcmah",
    "outputId": "11422b42-9072-49c8-d3e6-f0d40a405b4f"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # type: ignore\n",
    "import tensorflow as tf\n",
    "\n",
    "def preprocess_input_to_rgb(img):\n",
    "    # Check if the image already has 3 channels\n",
    "    if img.shape[-1] == 1:  # Grayscale images\n",
    "        img_tensor = tf.expand_dims(img, axis=-1)  # Ensure shape is (96, 96, 1)\n",
    "        return tf.image.grayscale_to_rgb(img_tensor)  # Convert to RGB (96, 96, 3)\n",
    "    elif img.shape[-1] == 3:  # Already RGB\n",
    "        return img  # No changes needed\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected input shape {img.shape}\")\n",
    "\n",
    "\n",
    "# Image data generators\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    preprocessing_function=preprocess_input_to_rgb,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2  # Use 20% of data for validation\n",
    ")\n",
    "\n",
    "# Training data generator\n",
    "train_generator = data_augmentation.flow_from_directory(\n",
    "    directory=train_path,       # Path to the training dataset\n",
    "    target_size=(96, 96),       # Resize images to 96x96\n",
    "    color_mode=\"grayscale\",           # Load as rgb images\n",
    "    batch_size=32,              # Batch size\n",
    "    class_mode=\"categorical\",   # Multi-class classification\n",
    "    subset=\"training\",          # Use the \"training\" subset\n",
    "    shuffle=True                # Shuffle data for training\n",
    ")\n",
    "\n",
    "# Validation data generator (uses the same augmentation instance with the \"validation\" subset)\n",
    "validation_generator = data_augmentation.flow_from_directory(\n",
    "    directory=train_path,\n",
    "    target_size=(96, 96),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"       # Use the \"validation\" subset\n",
    ")\n",
    "\n",
    "# Define the test ImageDataGenerator with the preprocessing function\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    preprocessing_function=preprocess_input_to_rgb  # Apply grayscale-to-RGB conversion\n",
    ")\n",
    "\n",
    "# Test data generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_path,\n",
    "    target_size=(96, 96),       # Resize test images to 96x96\n",
    "    color_mode=\"grayscale\",     # Load as grayscale images\n",
    "    batch_size=32,              # Batch size\n",
    "    class_mode=\"categorical\"    # Multi-class classification\n",
    ")\n",
    "\n",
    "# Key Validation Step: Verify the shape of the generated data\n",
    "x_batch, y_batch = next(test_generator)\n",
    "print(f\"Input batch shape: {x_batch.shape}\")  # Should output (batch_size, 96, 96, 3)\n",
    "\n",
    "# Display information about the detected classes\n",
    "print(f\"Classes detected: {train_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28gNGZFU0Wrb"
   },
   "source": [
    "### Verificacion del balance de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SoXj_q480ZTA",
    "outputId": "baeda10b-c9f1-45cc-d819-fe7d53cf0ea0"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Obtener el mapeo de índices a nombres de clases\n",
    "class_indices = train_generator.class_indices  # Diccionario {nombre_clase: índice_clase}\n",
    "index_to_class = {v: k for k, v in class_indices.items()}  # Invertir el diccionario\n",
    "\n",
    "# Contar las clases\n",
    "class_counts = Counter(train_generator.classes)\n",
    "\n",
    "# Ordenar por índice de clase y mostrar con nombres\n",
    "print(\"Distribución de clases en entrenamiento:\")\n",
    "for class_index, count in sorted(class_counts.items()):\n",
    "    class_name = index_to_class[class_index]  # Obtener el nombre asociado al índice\n",
    "    print(f\"{class_name}: {count} muestras\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de la distribución de pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "class_counts = Counter(train_generator.classes)\n",
    "plt.bar(class_counts.keys(), class_counts.values())\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.xlabel(\"Class Index\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abw8SjWG0_VI"
   },
   "source": [
    "### Cálculo de pesos del desbalance de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UTNmZGK41Bhq",
    "outputId": "90ebc4a8-7d52-48bd-b3d9-bd5affb12b9e"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Obtain class names and indices from the train generator\n",
    "class_indices = train_generator.class_indices  # Class-to-index mapping\n",
    "class_labels = list(class_indices.keys())  # Class names\n",
    "class_indices_inverted = {v: k for k, v in class_indices.items()}  # Index-to-class mapping\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.array(list(class_indices.values())),  # Use consistent class indices\n",
    "    y=train_generator.classes\n",
    ")\n",
    "\n",
    "# Map weights to class labels\n",
    "class_weights_dict = {class_indices_inverted[i]: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "# Print the computed weights\n",
    "print(\"Class Weights:\")\n",
    "for class_name, weight in class_weights_dict.items():\n",
    "    print(f\"{class_name}: {weight:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cnoh-hZfeMVP"
   },
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificación del entorno ejecutable (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0TpnCxSGpvQQ",
    "outputId": "8dd66151-711e-465b-d29d-6ee133bbe0c4"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Dispositivos disponibles:\")\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activación de uso de memoria dinámica de la GPU cuando sea posible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oa7zeOw4pzig"
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Configuración de memoria dinámica en GPU habilitada.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carpeta para el guardado del progreso del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"model_checkpoints\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cy8dbjUEnwHL"
   },
   "source": [
    "### Creación de la arquitectura base del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zSztOBLueOhY"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "\n",
    "# Dynamically determine the number of classes from the training data generator\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(96, 96, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z55AbpZE1rxh"
   },
   "source": [
    "### Compilación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 785
    },
    "id": "JBPvMWhi1tjc",
    "outputId": "9b7b26bc-3bc7-4fa5-83a7-f5a2e037aab4"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycNGmx4zoJwh"
   },
   "source": [
    "### Configuración de callbacks: Early stopping, un learning rate reducer y guardado del modelo para posterior uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTiS7LT8oGal"
   },
   "outputs": [],
   "source": [
    "# Callbacks for training\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=10, \n",
    "        restore_best_weights=True, \n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        min_lr=1e-6\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath=os.path.join(\"model_checkpoints\", \"best_model.keras\"), \n",
    "        save_best_only=True, \n",
    "        monitor='val_loss', \n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_k6qUVnoVjJ"
   },
   "source": [
    "### Entrenamiento del modelo personalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "id": "JRh2JyyfoXuN",
    "outputId": "eeceb53d-0961-4d66-c6b0-208494f4fdcc"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=50,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights_dict\n",
    ")\n",
    "\n",
    "# Save training history\n",
    "with open('training_history.json', 'w') as f:\n",
    "    json.dump(history.history, f)\n",
    "\n",
    "# Save the model in .keras format\n",
    "model.save('my_model.keras')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7mpnE3Yi2RA"
   },
   "source": [
    "## Visualización de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5vvR2Wazi5Ie"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the training history\n",
    "with open(\"training_history.json\", \"r\") as f:\n",
    "    history = json.load(f)  # This is already a dictionary\n",
    "\n",
    "# Plot and save accuracy and loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['accuracy'], label='Train Accuracy')  # Access the dictionary directly\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "plt.savefig(\"accuracy_plot.png\")  # Save the accuracy plot\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['loss'], label='Train Loss')  # Access the dictionary directly\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "plt.savefig(\"loss_plot.png\")  # Save the loss plot\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FoWHHa2GmTC5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class indices\n",
    "y_true = test_generator.classes  # True class labels\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(\n",
    "    y_true, \n",
    "    y_pred_classes, \n",
    "    target_names=list(test_generator.class_indices.keys())\n",
    ")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Save the classification report to a text file\n",
    "with open(\"classification_report.txt\", \"w\") as f:\n",
    "    f.write(\"Classification Report\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "print(cm)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=test_generator.class_indices.keys(), \n",
    "            yticklabels=test_generator.class_indices.keys())\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.savefig(\"confusion_matrix.png\")  # Save the confusion matrix plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
